{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d94e299-9815-46c3-9047-9f383933cc9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "modules loaded.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import urllib\n",
    "import datetime as dt\n",
    "from time import perf_counter\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import pyodbc\n",
    "import sqlalchemy as sqla\n",
    "\n",
    "import arcpy\n",
    "from arcgis.features import GeoAccessor, GeoSeriesAccessor\n",
    "\n",
    "def get_odbc_driver():\n",
    "    # gets name of ODBC driver, with name \"ODBC Driver <version> for SQL Server\"\n",
    "    drivers = [d for d in pyodbc.drivers() if 'ODBC Driver ' in d]\n",
    "    \n",
    "    if len(drivers) == 0:\n",
    "        errmsg = f\"ERROR. No usable ODBC Driver found for SQL Server.\" \\\n",
    "        f\"drivers found include {drivers}. Check ODBC Administrator program\" \\\n",
    "        \"for more information.\"\n",
    "        \n",
    "        raise Exception (errmsg)\n",
    "    else:\n",
    "        d_versions = [re.findall('\\d+', dv)[0] for dv in drivers] # [re.findall('\\d+', dv)[0] for dv in drivers]\n",
    "        latest_version = max([int(v) for v in d_versions])\n",
    "        driver = f\"ODBC Driver {latest_version} for SQL Server\"\n",
    "    \n",
    "        return driver\n",
    "\n",
    "driver = get_odbc_driver()\n",
    "\n",
    "print(\"modules loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "46480b88-b75e-4f74-83c8-b3765b6c19cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BASED ON TESTING, THIS IS A STILL SLOW BUT FASTER THAN ESRI CHUNK OF CODE TO RUN\n",
    "# A SQL QUERY AND LOAD DIRECTLY INTO AN ESRI FEATURE CLASS\n",
    "\n",
    "#-------------DEFINE PARAMETERS AND BUILD QUERY-----------------\n",
    "ilut_tbl = 'ilut_combined2020_63_DPS'  # \"TEST_DC_ilut_combined2020_63_DPS\"\n",
    "eto_tbl = 'raw_eto2020_DPS_latest'\n",
    "\n",
    "jnkey_ilut = 'PARCELID'\n",
    "ilut_cols = [jnkey_ilut, 'XCOORD', 'YCOORD', 'GISAc', 'JURIS', 'County', 'DU',\n",
    "             'POP_TOT', 'HH_hh', 'ENR_K12', 'EMPTOT', 'EMPFOOD', 'EMPRET', 'EMPSVC', 'EMPIND', \n",
    "            'PT_TOT_RES', 'SOV_TOT_RES', 'HOV_TOT_RES', 'TRN_TOT_RES', 'BIK_TOT_RES', 'WLK_TOT_RES', \n",
    "             'VMT_TOT_RES']\n",
    "ilut_cols = ', '.join(f\"ilut.{fname}\" for fname in ilut_cols)\n",
    "\n",
    "jnkey_eto = 'PARCELID'\n",
    "eto_cols = ['LU'] # exclude join key because you do not want duplicate columns\n",
    "eto_cols = ', '.join(f\"ilut.{fname}\" for fname in eto_cols)\n",
    "\n",
    "query_str = f\"\"\"SELECT\n",
    "    {ilut_cols},\n",
    "    {eto_cols}\n",
    "    FROM {ilut_tbl} ilut\n",
    "        JOIN {eto_tbl} eto\n",
    "            ON ilut.{jnkey_ilut} = eto.{jnkey_eto}\"\"\"\n",
    "\n",
    "rename_dict = {'DU': 'DU_TOT', 'LU': 'LUTYPE'}\n",
    "output_gdb = r'I:\\Projects\\Darren\\PPA3_GIS\\PPA3_GIS.gdb'\n",
    "\n",
    "lutag = ilut_tbl.split('ilut_combined')[1]\n",
    "out_tbl_name = f\"ppa_pclpnt{lutag}\"\n",
    "output_tbl = str(Path(output_gdb).joinpath(out_tbl_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7ab62398",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df chunk iterator created.\n",
      "creating feature class I:\\Projects\\Darren\\PPA3_GIS\\PPA3_GIS.gdb\\ppa_pclpnt2020_63_DPS...\n",
      "loading rows...\n",
      "\tupdated field LUTYPE to accommodate longer string value.\n",
      "\tupdated field JURIS to accommodate longer string value.\n",
      "\t100000 rows loaded...\n",
      "\tupdated field County to accommodate longer string value.\n",
      "\t200000 rows loaded...\n",
      "\t300000 rows loaded...\n",
      "\t400000 rows loaded...\n",
      "\t500000 rows loaded...\n",
      "\t600000 rows loaded...\n",
      "\t700000 rows loaded...\n",
      "\t800000 rows loaded...\n",
      "830280 rows inserted in 7.8 mins.\n",
      "output table - I:\\Projects\\Darren\\PPA3_GIS\\PPA3_GIS.gdb\\ppa_pclpnt2020_63_DPS\n"
     ]
    }
   ],
   "source": [
    "#---------CREATE ITERABLE DATAFRAME WITH CHUNKS----------------\n",
    "servername = 'SQL-SVR'\n",
    "dbname = 'MTP2024'\n",
    "trustedconn = 'yes'\n",
    "\n",
    "conn_str = f\"DRIVER={driver};\" \\\n",
    "        f\"SERVER={servername};\" \\\n",
    "        f\"DATABASE={dbname};\" \\\n",
    "        f\"Trusted_Connection={trustedconn}\"\n",
    "\n",
    "conn_str = urllib.parse.quote_plus(conn_str)\n",
    "engine = sqla.create_engine(f\"mssql+pyodbc:///?odbc_connect={conn_str}\")\n",
    "\n",
    "df_itr = pd.read_sql_query(sql=query_str, con=engine, chunksize=1000)\n",
    "print(\"df chunk iterator created.\")\n",
    "\n",
    "#------GO THROUGH CHUNKS AND LOAD INTO FEATURE CLASS-----------------\n",
    "st = perf_counter()\n",
    "\n",
    "rowcnt = 0\n",
    "for i, chunk in enumerate(df_itr):\n",
    "    chunk = chunk.rename(columns=rename_dict)\n",
    "    rowcnt += chunk.shape[0]\n",
    "    chunk_s = pd.DataFrame.spatial.from_xy(chunk, x_column='XCOORD', y_column='YCOORD', sr=2226)\n",
    "    if i == 0:\n",
    "        print(f\"creating feature class {output_tbl}...\")\n",
    "        chunk_s.spatial.to_featureclass(output_tbl, sanitize_columns=False)\n",
    "        out_tbl_fnames = [f.name for f in arcpy.ListFields(output_tbl)]\n",
    "        print(\"loading rows...\")\n",
    "    else:\n",
    "        drecs = chunk.to_dict(orient='records')\n",
    "        fields_to_use = [f for f in out_tbl_fnames if f in chunk.columns]\n",
    "        fields_to_use.append('SHAPE@XY')\n",
    "        with arcpy.da.InsertCursor(output_tbl, field_names=fields_to_use) as inscur:\n",
    "            for rec in drecs:\n",
    "                try:\n",
    "                    coords = (float(rec['XCOORD']), float(rec['YCOORD']))\n",
    "                    row = [rec[fname] for fname in out_tbl_fnames if fname in fields_to_use] # put into correct output order\n",
    "                    row.append(coords)\n",
    "                    inscur.insertRow(row)\n",
    "                except RuntimeError as rte:\n",
    "                    vlengths = {fname: len(v) for fname, v in rec.items() if isinstance(v, str)} # length of string vals in current row\n",
    "                    fclengths = {f.name: f.length for f in arcpy.ListFields(output_tbl)} # defined field lengths in feature class\n",
    "                    try:\n",
    "                        for f, fc_flen in fclengths.items():\n",
    "                            rowvlen = vlengths.get(f)\n",
    "                            if rowvlen and rowvlen > fc_flen: # if needed, update the fc field length to accommodate the new string val\n",
    "                                arcpy.management.AlterField(output_tbl, field=f, field_length=len(val))\n",
    "                                print(f\"\\tupdated field {f} to accommodate longer string value.\")\n",
    "                        inscur.insertRow(row)\n",
    "                    except:\n",
    "                        import pdb; pdb.set_trace()\n",
    "                    \n",
    "                    continue\n",
    "                    \n",
    "                    \n",
    "        if rowcnt % 100_000 == 0:\n",
    "            print(f\"\\t{rowcnt} rows loaded...\")\n",
    "                \n",
    "elapsed = round((perf_counter() - st) / 60, 1)\n",
    "print(f\"{rowcnt} rows inserted in {elapsed} mins.\")\n",
    "print(f\"output table - {output_tbl}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d35cb14a-99df-407d-98a0-aebd0377d417",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "updating EJ area tags for parcels...\n",
      "updated EJ tags.\n"
     ]
    }
   ],
   "source": [
    "# SPATIAL JOIN EJ DATA WITH FILTER APPLIED\n",
    "\n",
    "pcltbl = output_tbl\n",
    "pcl_ej_field = 'EJ_AREA'\n",
    "ej_layer = r'I:\\Projects\\Darren\\PPA3_GIS\\PPA3_GIS.gdb\\EJ_2025_final'\n",
    "\n",
    "fl_ej = 'fl_ej'\n",
    "fl_pcl = 'fl_pcl'\n",
    "\n",
    "for fl in [fl_ej, fl_pcl]:\n",
    "    if arcpy.Exists(fl): arcpy.management.Delete(fl)\n",
    "\n",
    "ej_fields = ['EJ_Label', 'Notes']\n",
    "arcpy.management.MakeFeatureLayer(ej_layer, fl_ej)\n",
    "\n",
    "ej_filter = \"EJ_Label <> 'Minority' Or Notes = 'Equity Priority Area'\"\n",
    "arcpy.management.SelectLayerByAttribute(fl_ej, where_clause=ej_filter)\n",
    "\n",
    "if pcl_ej_field not in [f.name for f in arcpy.ListFields(pcltbl)]:\n",
    "    arcpy.management.AddField(pcltbl, pcl_ej_field, 'SHORT')\n",
    "\n",
    "print(\"updating EJ area tags for parcels...\")\n",
    "arcpy.management.MakeFeatureLayer(pcltbl, fl_pcl)\n",
    "# set default to not be EJ area (0)\n",
    "with arcpy.da.UpdateCursor(fl_pcl, [pcl_ej_field]) as ucur:\n",
    "    for row in ucur:\n",
    "        row[0] = 0 # 1 = EJ area\n",
    "        ucur.updateRow(row)\n",
    "\n",
    "# then for parcels within EJ areas, set EJ=1\n",
    "arcpy.management.SelectLayerByLocation(fl_pcl, overlap_type='WITHIN', select_features=fl_ej)\n",
    "with arcpy.da.UpdateCursor(fl_pcl, [pcl_ej_field]) as ucur:\n",
    "    for row in ucur:\n",
    "        row[0] = 1 # 1 = is EJ area\n",
    "        ucur.updateRow(row)\n",
    "\n",
    "\n",
    "arcpy.management.SelectLayerByAttribute(fl_pcl, selection_type='CLEAR_SELECTION')\n",
    "\n",
    "print(\"updated EJ tags.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4586bf9e-169d-49f2-be30-63910c681419",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<geoprocessing field info object at 0x2d27e363990>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fi = arcpy.Describe(fl_ej).fieldInfo\n",
    "dir(fi)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5d94e299-9815-46c3-9047-9f383933cc9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "modules loaded.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import urllib\n",
    "import pandas as pd\n",
    "import pyodbc\n",
    "import sqlalchemy as sqla\n",
    "\n",
    "import arcpy\n",
    "from arcgis.features import GeoAccessor, GeoSeriesAccessor\n",
    "\n",
    "def get_odbc_driver():\n",
    "    # gets name of ODBC driver, with name \"ODBC Driver <version> for SQL Server\"\n",
    "    drivers = [d for d in pyodbc.drivers() if 'ODBC Driver ' in d]\n",
    "    \n",
    "    if len(drivers) == 0:\n",
    "        errmsg = f\"ERROR. No usable ODBC Driver found for SQL Server.\" \\\n",
    "        f\"drivers found include {drivers}. Check ODBC Administrator program\" \\\n",
    "        \"for more information.\"\n",
    "        \n",
    "        raise Exception (errmsg)\n",
    "    else:\n",
    "        d_versions = [re.findall('\\d+', dv)[0] for dv in drivers] # [re.findall('\\d+', dv)[0] for dv in drivers]\n",
    "        latest_version = max([int(v) for v in d_versions])\n",
    "        driver = f\"ODBC Driver {latest_version} for SQL Server\"\n",
    "    \n",
    "        return driver\n",
    "\n",
    "driver = get_odbc_driver()\n",
    "\n",
    "print(\"modules loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "46480b88-b75e-4f74-83c8-b3765b6c19cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df chunk iterator created.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "test_tbl = \"TEST_DC_ilut_combined2020_63_DPS\"\n",
    "\n",
    "ilut_cols = ['PARCELID', 'GISAc', 'JURIS', 'County', 'EJ_AREA', 'DU_TOT',\n",
    "             'POP_TOT', 'HH_hh', 'ENR_K12', 'EMPTOT', 'EMPFOOD', 'EMPRET', 'EMPSVC', 'EMPIND', \n",
    "            'PT_TOT_RES', 'SOV_TOT_RES', 'HOV_TOT_RES', 'TRN_TOT_RES', 'BIK_TOT_RES', 'WLK_TOT_RES', \n",
    "             'VMT_TOT_RES']\n",
    "eto_cols = ['PARCELID', 'LU']\n",
    "\n",
    "query_str = \"\"\"SELECT TOP 100 ilut.PARCELID, XCOORD, YCOORD, GISAc, ilut.JURIS, eto.LU\n",
    "    FROM TEST_DC_ilut_combined2020_63_DPS ilut\n",
    "        JOIN raw_eto2020_latest eto\n",
    "            ON ilut.PARCELID = eto.PARCELID\"\"\"\n",
    "\n",
    "output_tbl = r'I:\\Projects\\Darren\\PPA3_GIS\\PPA3_GIS.gdb\\TEST_SQL_EXPORT'\n",
    "\n",
    "#-----------------\n",
    "\n",
    "\n",
    "servername = 'SQL-SVR'\n",
    "dbname = 'MTP2024'\n",
    "trustedconn = 'yes'\n",
    "\n",
    "conn_str = f\"DRIVER={driver};\" \\\n",
    "        f\"SERVER={servername};\" \\\n",
    "        f\"DATABASE={dbname};\" \\\n",
    "        f\"Trusted_Connection={trustedconn}\"\n",
    "\n",
    "conn_str = urllib.parse.quote_plus(conn_str)\n",
    "engine = sqla.create_engine(f\"mssql+pyodbc:///?odbc_connect={conn_str}\")\n",
    "\n",
    "df_itr = pd.read_sql_query(sql=query_str, con=engine, chunksize=10)\n",
    "\n",
    "print(\"df chunk iterator created.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6cdb2e68-1619-49a5-89b1-1df095678fd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating feature class I:\\Projects\\Darren\\PPA3_GIS\\PPA3_GIS.gdb\\TEST_SQL_EXPORT...\n",
      "loading rows...\n",
      "completed.\n"
     ]
    }
   ],
   "source": [
    "for i, chunk in enumerate(df_itr):\n",
    "    chunk_s = pd.DataFrame.spatial.from_xy(chunk, x_column='XCOORD', y_column='YCOORD', sr=2226)\n",
    "    if i == 0:\n",
    "        print(f\"creating feature class {output_tbl}...\")\n",
    "        chunk_s.spatial.to_featureclass(output_tbl, sanitize_columns=False)\n",
    "        out_tbl_fnames = [f.name for f in arcpy.ListFields(output_tbl)]\n",
    "        print(\"loading rows...\")\n",
    "    else:\n",
    "        drecs = chunk.to_dict(orient='records')\n",
    "        fields_to_use = [f for f in out_tbl_fnames if f in chunk.columns]\n",
    "        fields_to_use.append('SHAPE@XY')\n",
    "        with arcpy.da.InsertCursor(output_tbl, field_names=fields_to_use) as inscur:\n",
    "            for rec in drecs:\n",
    "                coords = (float(rec['XCOORD']), float(rec['YCOORD']))\n",
    "                row = [rec[fname] for fname in out_tbl_fnames if fname in fields_to_use] # put into correct output order\n",
    "                row.append(coords)\n",
    "                # import pdb; pdb.set_trace()\n",
    "                inscur.insertRow(row)\n",
    "                \n",
    "\n",
    "print(\"completed.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
